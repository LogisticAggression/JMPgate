{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "from reNN.base import *\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndims = 100\n",
    "set_size = 10000\n",
    "\n",
    "embedding_dir = \"/Users/rob/ML_Data/x86_vectors/lstm/\"+str(ndims)+\"/\"\n",
    "#embedding_dir = \"/Users/rob/ML_Data/x86_vectors/lstm/\"+str(ndims)+\"-raw/\"\n",
    "#embedding_dir = \"/Users/rob/ML_Data/x86_vectors/byte_3grams/500/\"\n",
    "#label_dir = \"/Users/rob/ML_Data/x86_vectors/byte_3grams/labels/\"\n",
    "reNN_dir = \"/Users/rob/ML_Data/code_standard/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6354\n"
     ]
    }
   ],
   "source": [
    "all_reNN_files = []\n",
    "\n",
    "for root, dir, files in os.walk(reNN_dir):\n",
    "    for f in files:\n",
    "        all_reNN_files.append(root+\"/\"+f)\n",
    "        \n",
    "print len(all_reNN_files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345092\n",
      "747611\n",
      "set([u'gcc', u'visual studio'])\n"
     ]
    }
   ],
   "source": [
    "loader = reNN_binary()\n",
    "\n",
    "\n",
    "collections = []\n",
    "class1_funcs = []\n",
    "class2_funcs = []\n",
    "\n",
    "#class1_types = [\"reactos\", \"windows10\"]\n",
    "#class2_types = [\"Arch_Linux\"]\n",
    "\n",
    "class1_types = [\"visual studio\"]\n",
    "class2_types = [\"gcc\"]\n",
    "\n",
    "for fname in tqdm(all_reNN_files):\n",
    "    try:\n",
    "        loader = loader.load(fname)\n",
    "    except:\n",
    "        continue\n",
    "    for func in loader.functions:\n",
    "        collections.append(loader.cc_name)\n",
    "        if loader.functions[func][1] > 20:\n",
    "            if loader.cc_name in class1_types:\n",
    "                class1_funcs.append(loader.md5+\":\"+loader.name+\":\"+func)\n",
    "            elif loader.cc_name in class2_types:\n",
    "                class2_funcs.append(loader.md5+\":\"+loader.name+\":\"+func)\n",
    "                \n",
    "print len(class1_funcs)\n",
    "print len(class2_funcs)\n",
    "print set(collections)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_labels(label_file):\n",
    "    labels = []\n",
    "    with open(label_file, \"r\") as lfile:\n",
    "        for line in lfile:\n",
    "            labels.append(''.join([i + \":\" for i in line.split(\":\")[1:]])[:-1].strip())\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_set(func_names, ndims):\n",
    "    functions_by_hash = {}\n",
    "    func_names.sort()\n",
    "    counter = 0\n",
    "    data_matrix = np.zeros((len(func_names), ndims))\n",
    "    for f in func_names:\n",
    "        file_hash = f.split(\":\")[0]\n",
    "        function_name = ''.join([i + \":\" for i in f.split(\":\")[2:]])[:-1]\n",
    "        try:\n",
    "            functions_by_hash[file_hash].append(function_name)\n",
    "        except:\n",
    "            functions_by_hash[file_hash] = [function_name]\n",
    "    for file_hash in functions_by_hash:\n",
    "        try:\n",
    "            buff = np.load(embedding_dir+file_hash+\".npy\")\n",
    "            buff_labels = load_labels(label_dir+file_hash+\".labels\")\n",
    "        except:\n",
    "            continue\n",
    "        indexes = []\n",
    "        for func_name in functions_by_hash[file_hash]:\n",
    "            try:\n",
    "                indexes.append(buff_labels.index(func_name))\n",
    "            except:\n",
    "                continue\n",
    "        for i in indexes:\n",
    "            data_matrix[counter] = buff[i]\n",
    "            counter = counter + 1\n",
    "    buff = data_matrix[:counter]\n",
    "    return buff\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loop 0...\n",
      "(221865, 100)\n",
      "(235590, 100)\n",
      "[0 0 0 ..., 1 1 1]\n",
      "(55522, 100)\n",
      "(58922, 100)\n",
      "[0 0 0 ..., 1 1 1]\n",
      "Loop completed in 633.475 seconds\n",
      "Starting loop 1...\n",
      "(221932, 100)\n",
      "(235635, 100)\n",
      "[0 0 0 ..., 1 1 1]\n",
      "(55418, 100)\n",
      "(58950, 100)\n",
      "[0 0 0 ..., 1 1 1]\n",
      "Loop completed in 619.382 seconds\n",
      "Starting loop 2...\n",
      "(221954, 100)\n",
      "(235646, 100)\n",
      "[0 0 0 ..., 1 1 1]\n",
      "(55422, 100)\n",
      "(58919, 100)\n",
      "[0 0 0 ..., 1 1 1]\n",
      "Loop completed in 618.709 seconds\n",
      "Starting loop 3...\n",
      "(221819, 100)\n",
      "(235710, 100)\n",
      "[0 0 0 ..., 1 1 1]\n",
      "(55528, 100)\n",
      "(58879, 100)\n",
      "[0 0 0 ..., 1 1 1]\n",
      "Loop completed in 610.220 seconds\n",
      "Starting loop 4...\n",
      "(221904, 100)\n",
      "(235600, 100)\n",
      "[0 0 0 ..., 1 1 1]\n",
      "(55465, 100)\n",
      "(58941, 100)\n",
      "[0 0 0 ..., 1 1 1]\n",
      "Loop completed in 563.229 seconds\n",
      "Starting loop 5...\n",
      "(221798, 100)\n",
      "(235720, 100)\n",
      "[0 0 0 ..., 1 1 1]\n",
      "(55546, 100)\n",
      "(58888, 100)\n",
      "[0 0 0 ..., 1 1 1]\n",
      "Loop completed in 539.837 seconds\n",
      "Starting loop 6...\n",
      "(221960, 100)\n",
      "(235601, 100)\n",
      "[0 0 0 ..., 1 1 1]\n",
      "(55444, 100)\n",
      "(58948, 100)\n",
      "[0 0 0 ..., 1 1 1]\n",
      "Loop completed in 540.188 seconds\n",
      "Starting loop 7...\n",
      "(221937, 100)\n",
      "(235601, 100)\n",
      "[0 0 0 ..., 1 1 1]\n",
      "(55499, 100)\n",
      "(58953, 100)\n",
      "[0 0 0 ..., 1 1 1]\n",
      "Loop completed in 536.942 seconds\n",
      "Starting loop 8...\n",
      "(221837, 100)\n",
      "(235648, 100)\n",
      "[0 0 0 ..., 1 1 1]\n",
      "(55573, 100)\n",
      "(58891, 100)\n",
      "[0 0 0 ..., 1 1 1]\n",
      "Loop completed in 534.113 seconds\n",
      "Starting loop 9...\n",
      "(221881, 100)\n",
      "(235656, 100)\n",
      "[0 0 0 ..., 1 1 1]\n",
      "(55529, 100)\n",
      "(58935, 100)\n",
      "[0 0 0 ..., 1 1 1]\n",
      "Loop completed in 535.139 seconds\n"
     ]
    }
   ],
   "source": [
    "def test_data_set\n",
    "    scores = []\n",
    "    for i in range(0,10):\n",
    "        print \"Starting loop %d...\" % i\n",
    "        start = time.time()\n",
    "        class1_sample = random.sample(class1_funcs, 300000)\n",
    "        class2_sample = random.sample(class2_funcs, 300000)\n",
    "\n",
    "        class1_train_names = class1_sample[:240000]\n",
    "        class2_train_names = class2_sample[:240000]\n",
    "        class1_test_names = class1_sample[240000:]\n",
    "        class2_test_names = class2_sample[240000:]\n",
    "\n",
    "        class1_train = load_data_set(class1_train_names, ndims)\n",
    "        class2_train = load_data_set(class2_train_names, ndims)\n",
    "        train_classes = np.zeros(class1_train.shape[0]+class2_train.shape[0], dtype = np.int16)\n",
    "        train_classes[class1_train.shape[0]:] = 1\n",
    "        train_data = np.concatenate((class1_train, class2_train))\n",
    "        print class1_train.shape\n",
    "        print class2_train.shape\n",
    "        print train_classes\n",
    "\n",
    "        class1_test = load_data_set(class1_test_names, ndims)\n",
    "        class2_test = load_data_set(class2_test_names, ndims)\n",
    "        test_classes = np.zeros(class1_test.shape[0]+class2_test.shape[0], dtype = np.int16)\n",
    "        test_classes[class1_test.shape[0]:] = 1\n",
    "        test_data = np.concatenate((class1_test, class2_test))\n",
    "        print class1_test.shape\n",
    "        print class2_test.shape\n",
    "        print test_classes\n",
    "\n",
    "        classifier = RandomForestClassifier()\n",
    "        classifier.fit(train_data, train_classes)\n",
    "\n",
    "        scores.append(classifier.score(test_data, test_classes))\n",
    "        print \"Loop completed in %.3f seconds\" % (time.time() - start)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9947\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracy: %.4f\" % (sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "from reNN.base import *\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndims = 500\n",
    "set_size = 10000\n",
    "\n",
    "#embedding_dir = \"/Users/rob/ML_Data/x86_vectors/lstm/\"+str(ndims)+\"/\"\n",
    "#label_dir = embedding_dir\n",
    "#embedding_dir = \"/Users/rob/ML_Data/x86_vectors/lstm/\"+str(ndims)+\"-raw/\"\n",
    "embedding_dir = \"/Users/rob/ML_Data/x86_vectors/byte_3grams/500/\"\n",
    "label_dir = \"/Users/rob/ML_Data/x86_vectors/byte_3grams/labels/\"\n",
    "reNN_dir = \"/Users/rob/ML_Data/code_standard/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6354\n"
     ]
    }
   ],
   "source": [
    "all_reNN_files = []\n",
    "\n",
    "for root, dir, files in os.walk(reNN_dir):\n",
    "    for f in files:\n",
    "        all_reNN_files.append(root+\"/\"+f)\n",
    "        \n",
    "print len(all_reNN_files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133481\n",
      "211611\n",
      "549625\n",
      "197986\n",
      "set([u'-O3', u'debug', u'-O1', u'release'])\n"
     ]
    }
   ],
   "source": [
    "loader = reNN_binary()\n",
    "\n",
    "\n",
    "collections = []\n",
    "class1_funcs = []\n",
    "class2_funcs = []\n",
    "class3_funcs = []\n",
    "class4_funcs = []\n",
    "\n",
    "#class1_types = [\"reactos\", \"windows10\"]\n",
    "#class2_types = [\"Arch_Linux\"]\n",
    "\n",
    "class1_types = [\"visual studio\"]\n",
    "class2_types = [\"gcc\"]\n",
    "\n",
    "for fname in tqdm(all_reNN_files):\n",
    "    try:\n",
    "        loader = loader.load(fname)\n",
    "    except:\n",
    "        continue\n",
    "    for func in loader.functions:\n",
    "        collections.append(loader.cc_flags)\n",
    "        if loader.functions[func][1] > 20:\n",
    "            if loader.cc_name == \"visual studio\":\n",
    "                if loader.cc_flags == \"debug\":\n",
    "                    class1_funcs.append(loader.md5+\":\"+loader.name+\":\"+func)\n",
    "                else:\n",
    "                    class2_funcs.append(loader.md5+\":\"+loader.name+\":\"+func)\n",
    "            elif loader.cc_name == \"gcc\":\n",
    "                if loader.cc_flags == \"-O1\":\n",
    "                    class3_funcs.append(loader.md5+\":\"+loader.name+\":\"+func)\n",
    "                else:\n",
    "                    class4_funcs.append(loader.md5+\":\"+loader.name+\":\"+func)\n",
    "                    \n",
    "print len(class1_funcs)\n",
    "print len(class2_funcs)\n",
    "print len(class3_funcs)\n",
    "print len(class4_funcs)\n",
    "print set(collections)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_labels(label_file):\n",
    "    labels = []\n",
    "    with open(label_file, \"r\") as lfile:\n",
    "        for line in lfile:\n",
    "            labels.append(''.join([i + \":\" for i in line.split(\":\")[1:]])[:-1].strip())\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_set(func_names, ndims):\n",
    "    functions_by_hash = {}\n",
    "    func_names.sort()\n",
    "    counter = 0\n",
    "    data_matrix = np.zeros((len(func_names), ndims))\n",
    "    for f in func_names:\n",
    "        file_hash = f.split(\":\")[0]\n",
    "        function_name = ''.join([i + \":\" for i in f.split(\":\")[2:]])[:-1]\n",
    "        try:\n",
    "            functions_by_hash[file_hash].append(function_name)\n",
    "        except:\n",
    "            functions_by_hash[file_hash] = [function_name]\n",
    "    for file_hash in functions_by_hash:\n",
    "        try:\n",
    "            buff = np.load(embedding_dir+file_hash+\".npy\")\n",
    "            buff_labels = load_labels(label_dir+file_hash+\".labels\")\n",
    "        except:\n",
    "            continue\n",
    "        indexes = []\n",
    "        for func_name in functions_by_hash[file_hash]:\n",
    "            try:\n",
    "                indexes.append(buff_labels.index(func_name))\n",
    "            except:\n",
    "                continue\n",
    "        for i in indexes:\n",
    "            data_matrix[counter] = buff[i]\n",
    "            counter = counter + 1\n",
    "    buff = data_matrix[:counter]\n",
    "    return buff\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_data_set():\n",
    "    hard_matches = []\n",
    "    soft_matches = []\n",
    "    for i in range(0,1):\n",
    "        print \"Starting loop %d...\" % i\n",
    "        start = time.time()\n",
    "        class1_sample = random.sample(class1_funcs, 100000)\n",
    "        class2_sample = random.sample(class2_funcs, 100000)\n",
    "        class3_sample = random.sample(class3_funcs, 100000)\n",
    "        class4_sample = random.sample(class4_funcs, 100000)\n",
    "\n",
    "        class1_train_names = class1_sample[:80000]\n",
    "        class2_train_names = class2_sample[:80000]\n",
    "        class3_train_names = class3_sample[:80000]\n",
    "        class4_train_names = class4_sample[:80000]\n",
    "        class1_test_names = class1_sample[80000:]\n",
    "        class2_test_names = class2_sample[80000:]\n",
    "        class3_test_names = class3_sample[80000:]\n",
    "        class4_test_names = class4_sample[80000:]\n",
    "\n",
    "        class1_train = load_data_set(class1_train_names, ndims)\n",
    "        class2_train = load_data_set(class2_train_names, ndims)\n",
    "        class3_train = load_data_set(class3_train_names, ndims)\n",
    "        class4_train = load_data_set(class4_train_names, ndims)\n",
    "        train_classes = np.zeros(class1_train.shape[0]+class2_train.shape[0]+\n",
    "                                 class3_train.shape[0]+class4_train.shape[0], dtype = np.int16)\n",
    "        c2_offset = class1_train.shape[0]\n",
    "        c3_offset = c2_offset + class2_train.shape[0]\n",
    "        c4_offset = c3_offset + class3_train.shape[0]\n",
    "        train_classes[c2_offset:c3_offset] = 1\n",
    "        train_classes[c3_offset:c4_offset] = 2\n",
    "        train_classes[c4_offset:] = 3\n",
    "        train_data = np.concatenate((class1_train, class2_train, class3_train, class4_train))\n",
    "        print class1_train.shape\n",
    "        print class2_train.shape\n",
    "        print class3_train.shape\n",
    "        print class4_train.shape\n",
    "        print train_classes\n",
    "\n",
    "        class1_test = load_data_set(class1_test_names, ndims)\n",
    "        class2_test = load_data_set(class2_test_names, ndims)\n",
    "        class3_test = load_data_set(class3_test_names, ndims)\n",
    "        class4_test = load_data_set(class4_test_names, ndims)\n",
    "        test_classes = np.zeros(class1_test.shape[0]+class2_test.shape[0]+\n",
    "                                class3_test.shape[0]+class4_test.shape[0], dtype = np.int16)\n",
    "        c2_offset = class1_test.shape[0]\n",
    "        c3_offset = c2_offset + class2_test.shape[0]\n",
    "        c4_offset = c3_offset + class3_test.shape[0]\n",
    "        test_classes[c2_offset:c3_offset] = 1\n",
    "        test_classes[c3_offset:c4_offset] = 2\n",
    "        test_classes[c4_offset:] = 3\n",
    "        test_data = np.concatenate((class1_test, class2_test, class3_test, class4_test))\n",
    "        print class1_test.shape\n",
    "        print class2_test.shape\n",
    "        print test_classes\n",
    "\n",
    "        classifier = LogisticRegression(multi_class=\"multinomial\", solver=\"sag\")\n",
    "        classifier.fit(train_data, train_classes)\n",
    "\n",
    "\n",
    "        probs = classifier.predict_proba(test_data)\n",
    "        hard = 0\n",
    "        soft = 0\n",
    "\n",
    "        for p in xrange(0,test_data.shape[0]):\n",
    "            pred = np.argmax(probs[p])\n",
    "            if pred == test_classes[p]:\n",
    "                hard = hard + 1\n",
    "            if pred == 0 or pred == 1 and test_classes[p] == 0 or test_classes[p] == 1:\n",
    "                soft = soft + 1\n",
    "            if pred == 2 or pred == 3 and test_classes[p] == 2 or test_classes[p] == 3:\n",
    "                soft = soft + 1\n",
    "\n",
    "        print float(soft)/test_data.shape[0]\n",
    "        print float(hard)/test_data.shape[0]\n",
    "        soft_matches.append(float(soft)/test_data.shape[0])\n",
    "        hard_matches.append(float(hard)/test_data.shape[0])\n",
    "        print \"Loop completed in %.3f seconds\" % (time.time() - start)\n",
    "    return soft_matches, hard_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loop 0...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2049 is out of bounds for axis 0 with size 2049",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-539ea018d09d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-ed44ac1e5e91>\u001b[0m in \u001b[0;36mtest_data_set\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mclass4_test_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass4_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m80000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mclass1_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass1_train_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mclass2_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass2_train_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mclass3_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass3_train_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-42d2ef5b0ed6>\u001b[0m in \u001b[0;36mload_data_set\u001b[0;34m(func_names, ndims)\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mdata_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mbuff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2049 is out of bounds for axis 0 with size 2049"
     ]
    }
   ],
   "source": [
    "scores = test_data_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs = classifier.predict_proba(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hard = 0\n",
    "soft = 0\n",
    "\n",
    "for p in xrange(0,test_data.shape[0]):\n",
    "    pred = np.argmax(probs[p])\n",
    "    if pred == test_classes[p]:\n",
    "        hard = hard + 1\n",
    "    if pred == 0 or pred == 1 and test_classes[p] == 0 or test_classes[p] == 1:\n",
    "        soft = soft + 1\n",
    "    if pred == 2 or pred == 3 and test_classes[p] == 2 or test_classes[p] == 3:\n",
    "        soft = soft + 1\n",
    "        \n",
    "print float(soft)/test_data.shape[0]\n",
    "print float(hard)/test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print test_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
